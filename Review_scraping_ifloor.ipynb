{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions \n",
    "\n",
    "\n",
    "def get_reviews():\n",
    "    # initiate beautiful soup parser\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html.encode('utf-8'),\"html.parser\")\n",
    "\n",
    "\n",
    "    # find review card\n",
    "    divs = soup.select(\"body div#a-page div#cm_cr-review_list div[data-hook=review]\")\n",
    "\n",
    "    # iterate review card to get data\n",
    "    for idx, div in enumerate(divs):\n",
    "        # initiate variables\n",
    "        account_name = None\n",
    "        score = None\n",
    "        title = None\n",
    "        Location = None\n",
    "        date = None\n",
    "        product = None\n",
    "        purchase_status = None\n",
    "        review_content = None\n",
    "        number_like = None\n",
    "\n",
    "        # get account name\n",
    "        span_account = div.select(\"div.a-profile-content span.a-profile-name\")\n",
    "        if span_account != []:\n",
    "            account_name = span_account[0].get_text()\n",
    "\n",
    "        # get score\n",
    "        a_score = div.select(\"div.a-row i.a-icon span.a-icon-alt\")\n",
    "        if a_score != []:\n",
    "            score = a_score[0].get_text()\n",
    "\n",
    "        # get title        \n",
    "        span_title = div.select(\"a[data-hook=review-title] span\")\n",
    "        if span_title == []:\n",
    "            span_title = div.select(\"span[data-hook=review-title] span\")\n",
    "        if span_title != []:\n",
    "            title = span_title[0].get_text()\n",
    "\n",
    "        # get location and date\n",
    "        span_location_date = div.select(\"span[data-hook=review-date]\")\n",
    "        if span_location_date != []:\n",
    "            span_content = span_location_date[0].get_text().strip()\n",
    "        pattern = r'Reviewed in (.+) on (.+)'\n",
    "        m = re.match(pattern, span_content)\n",
    "        Location = m.group(1)\n",
    "        date = m.group(2)\n",
    "#         Location = re.findall(r'Reviewed in ([^o]+)', span_content)[0].strip()\n",
    "#         date = re.findall(r'on ([^\"]+)', span_content)[0].strip()\n",
    "\n",
    "#         # get product\n",
    "#         a_product = div.select(\"div a[data-hook=format-strip]\")\n",
    "#         if a_product != []:\n",
    "        product = \"iFLOOR\"\n",
    "\n",
    "        # get purchase status\n",
    "        span_purchase = div.select(\"span.a-declarative span[data-hook=avp-badge]\")\n",
    "        if span_purchase != []:\n",
    "            purchase_status = span_purchase[0].get_text()\n",
    "\n",
    "        # get review content\n",
    "        span_content = div.select(\"span[data-hook=review-body] span\") # tags of English country\n",
    "        if span_content != []:\n",
    "            review_content = span_content[-1].get_text().strip()\n",
    "        if review_content == \"\":\n",
    "            span_content = div.select(\"span[data-hook=review-body] span.cr-original-review-content\") # non-English country\n",
    "            if span_content != []:\n",
    "                review_content = span_content[-1].get_text().strip()\n",
    "        \n",
    "        # get number of likes\n",
    "        span_like = div.select(\"span.cr-vote span[data-hook=helpful-vote-statement]\")\n",
    "        if span_like != []:\n",
    "            number_like = span_like[0].get_text()[:-26]\n",
    "\n",
    "        rows.append([account_name, score, title, Location, date, product, purchase_status, review_content, number_like])\n",
    "\n",
    "    try:\n",
    "        next_link = soup.select(\"div#cm_cr-review_list div.a-form-actions span.a-declarative ul.a-pagination li.a-last a\")[0]['href']\n",
    "        return 'https://www.amazon.com' + next_link\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # initiate selenium webdriver and get the page\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get('https://www.amazon.com/Cordless-Cleaner-Powerful-Lightweight-Self-Cleaning/product-reviews/B07M5SND7X/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&language=en_US&reviewerType=all_reviews')\n",
    "    # create list used to store data\n",
    "    rows = []\n",
    "        \n",
    "    while True:\n",
    "        new_link = get_reviews()\n",
    "        if new_link == \"\":\n",
    "            break\n",
    "        else:\n",
    "            driver.get(new_link)\n",
    "\n",
    "    \n",
    "    \n",
    "    # write to file\n",
    "    headers = ['Account_name','Score','Title','Location','Date', 'Product', 'Purchase_Status', 'Review_content', 'Like']\n",
    "\n",
    "    with open('test2.csv','w', encoding=\"utf-8\", newline='')as f:\n",
    "        f_csv = csv.writer(f)\n",
    "        f_csv.writerow(headers)\n",
    "        f_csv.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
